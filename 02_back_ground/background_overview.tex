\section{2D LiDARを用いた人検出手法}
2D LiDARを用いた研究では，取得した水平断面の点群データをクラスタリングし，脚部や
胴体の断面形状として検出した後，カルマンフィルタ等を用いて時系列的な追跡を行う
手法が多い．
Arrasら\cite{Using Boosted Features for the Detection of People in 2D Range Data}は
、2Dレーザーレンジファインダ（LRF）から得られる平面スキャンデータを用いて、
複雑な環境下でもロバストに人物を検出する手法を提案している。従来の多くのアプ
ローチは、人の脚を検出・追跡するために事前に定義された特徴量を使用していたが、
これらは手動での設計や調整に依存しているという課題があった。
これに対しArrasらは、多数の特徴量から有効なものを教師あり学習によって選択・統合
するアプローチにより、環境に適応した高精度な検出器を構築している。

提案手法では、まずLRFから取得された点群データに対し、隣接するビーム間の距離が一定
以上離れた箇所で分割する「ジャンプディスタンス条件」を用いてセグメント化を行う。
得られた各セグメントを脚の候補とし、その形状や統計的性質を表す14種類のスカラー特徴
量を算出している。具体的には、セグメントを構成する点数、標準偏差、外れ値に強い
指標である中央値からの平均偏差、隣接セグメントへのジャンプ距離、セグメント幅、
最小二乗法による直線および円への適合度（直線性・円形度）、適合円の半径、境界長、
境界の規則性、平均曲率、境界の凸性を測る平均角度差といった静的な幾何学的特徴に
加え、連続するスキャン間の差分から算出される平均速度という動的特徴が定義されている。

学習アルゴリズムにはAdaBoostを採用し、これらの単純な特徴量（弱い識別器）を組み合わ
せることで、人の脚に対応するセグメントとそうでないものを判別する強い識別器を構築
している。AdaBoostを用いることで、識別性能を最大化するように、最も情報量の多い
特徴量と最適な閾値をデータから自動的に学習することが可能となる。

実験は、静止した人物や移動する人物が存在する廊下や散らかったオフィス環境に
おいて実施された。学習された識別器の性能評価の結果、家具や物体が多く存在する複雑
な環境下においても、90\%を超える高い正解率で人物を検出できることが示されている。
特に、従来研究で頻繁に用いられる幾何学的ルール（脚の幅やジャンプ距離に固定閾値を
設ける手法など）に基づくヒューリスティックな手法との比較において、提案手法は誤検出
率を大幅に低減させ、その優位性を実証している。また、ある環境で学習させた識別器を、
学習データに含まれていない未知の環境に適用した場合でも高い精度が維持されており、
学習されたモデルが高い汎用性を有していることが確認された。

さらに、学習された識別器の分析を通じて、人検出に有効な特徴量に関する重要な知見が得
られている。AdaBoostによって選択された特徴量の重みを分析した結果、最も識別に寄与
していたのは、単純な脚の幅や円形度ではなく、フィッティングされた円の「半径」および
セグメントの「凸性（平均角度差）」であった。これは、2Dスキャンデータにおける脚の
形状が、必ずしも綺麗な円弧や直線ではなく多様な形状をとる中で、サイズ感と外側への
膨らみ具合が最もロバストな指標であることを示唆している。加えて、動的特徴である
「移動速度」を追加した場合の実験結果から、静的な幾何学的特徴のみを用いた場合と比較
して精度の向上はわずかであることが示された。このことからArrasらは、静止している
人物も含めたロバストな検出を行う上では、移動情報は必須ではなく、適切な幾何学的特徴
の組み合わせだけで十分に高精度な検出が可能であると結論付けているが、オクルージョン
後の再検出や追従復帰については言及されていない。



\section{3D LiDARを用いた人追従手法}
3D LiDARを用いた研究では，3次元空間の点群データから地面点群を除去し，ユークリッド
クラスタリング等を用いて人物候補となる点群クラスタを抽出した後，カルマンフィルタや
パーティクルフィルタを用いて追跡するパイプラインが多い。Yanら
\cite{Online learning for 3D LiDAR-based human detection: experimental analysis 
of point cloud clustering and classification methods}
は、3D LiDARを搭載した移動ロボットが、走行環境に適応しながら人物検出器をオンライン
で学習するフレームワークを提案している。3D LiDARを用いた人物検出において、距離に
よる点群密度の変化や、学習データの作成にかかる人的コスト（アノテーションの手間）は
大きな課題であった。これに対しYanらは、少数のラベル付きデータで初期化した識別器
（SVM）を、ロボットの稼働中に得られるデータを用いて自動的に再学習させる手法を開発
した。

提案手法の核となるのは、適応的なクラスタリング手法と「P-N Experts」と呼ばれる教師
データ生成メカニズムである。まず、点群のセグメンテーション（クラスタリング）において、
LiDARからの距離に応じて疎になる点群密度に対応するため、センサを中心とした同心円状の
領域ごとに異なる距離閾値を設定する適応的クラスタリングを採用している。これにより、
近距離の密な点群と遠距離の疎な点群の双方において、ユークリッド距離に基づく従来手法
や深度画像ベースの手法よりも高精度な切り出しを実現している。

人物識別においては、幾何学的な特徴量を用いたSVM分類器が採用されているが、特に遠距
離における検出性能を向上させるため、点群を高さ方向に10個のスライスに分割し、各スラ
イスの幅や奥行きを記述する「スライス特徴量（Slice feature）」を新たに導入している。
これにより、点数が少ない遠方の人物に対してもロバストな特徴抽出が可能となっている。

オンライン学習のプロセスでは、マルチターゲット追跡（UKF）の結果を利用して、識別器
の誤りを自動的に修正する。具体的には、「P-expert」が追跡軌跡の連続性を利用して検出
漏れ（False Negatives）を拾い上げて正例として追加し、「N-expert」が静止物体などの
誤検出（False Positives）を特定して負例として追加する。このようにして自動生成され
た学習データを用いて識別器を定期的に再学習させることで、人手による追加のアノテーシ
ョンなしに、環境特有の人物や背景の特徴に適応していくことが可能である。

大規模な屋内環境で取得されたデータセット（L-CAS 3D Point Cloud People Dataset）を
用いた評価実験の結果、提案された適応的クラスタリングは従来手法と比較して高いセグメ
ンテーション精度を示し、また、オンライン学習によって更新された識別器は、オフライン
で手動学習された識別器よりも高いF値（精度と再現率の調和平均）を達成することが確認
されている。Yanらの研究は、3D LiDARを用いた人物検出において、幾何学的特徴量の有効性
と、追跡情報をフィードバックループに組み込むことによる自己教師あり学習の有用性を
示した重要な成果であるが、オクルージョン後の再検出や識別については言及されていない。



\section{単眼カメラを用いたオクルージョンを考慮した人追従手法}
カメラ（RGB画像）を用いた人追従システムは、対象の色やテクスチャといった豊富な光学
的情報（Photometric features）を活用できる点が特徴である．初期の研究では，色ヒス
トグラムやHOG (Histogram of Oriented Gradients) 特徴量を用いた検出手法が主流であ
ったが，近年では深層学習（Deep Learning）と追跡アルゴリズムを組み合わせた手法が広
く研究されている．また，事前学習済みモデルをそのまま用いるのではなく，環境や対象
に応じて適応するオンライン学習を取り入れたアプローチも提案されている．Koideら
\cite{Monocular Person Tracking and Identification with On-line Deep Feature 
Selection for Person Following Robots}
は、LiDARやRGB-Dカメラと比較して安価で導入が容易な「単眼カメラ」のみを用いた移動
ロボットの人追従システムを提案している。

単眼カメラを用いた人追従においては、主に二つの技術的課題が存在する。第一の課題は、
「奥行き情報が得られない画像から、いかに対象の3次元位置を正確に推定するか」という
点である。第二の課題は、「計算リソースの限られたロボット上で、照明変動や姿勢変化に
頑健な追跡をリアルタイムで実現するか」という点である。従来、計算コストの低いHOG
特徴量やカラーヒストグラムを用いた手法（KCFなど）は高速であるが、照明変化や背景と
の同化に脆弱であった。一方で、深層学習（CNN）を用いた手法は高い識別能力を持つもの
の計算負荷が極めて高く、組み込みGPUを搭載したモバイルロボットでのリアルタイム動作
は困難であった。

これらの課題に対し、Koideらは以下の二つのアプローチを統合することで解決を図ってい
る。

第一に、3次元位置推定の課題に対しては、深層学習ベースの骨格検出（OpenPose）と幾何
学的拘束を組み合わせた追跡フレームワークを導入している。具体的には、画像上で検出さ
れた人物の「足首」と「首」の位置に着目し、これらが地平面（Ground Plane）上に存在す
るという仮定と、カルマンフィルタ（UKF）による身長推定を組み合わせることで、距離セ
ンサを用いずに高精度なロボット座標系での位置推定を実現した。この手法は、足元が障害
物で隠れた場合（オクルージョン）でも、首の位置情報を用いて追跡を継続できる利点を
持つ。

第二に、計算コストと堅牢性のトレードオフに対しては、「オンライン深層特徴選択
（ODFS: On-line Deep Feature Selection）」という手法を提案している。これは、
ImageNetで事前学習されたVGG-16モデルから得られる膨大な特徴マップ（Convolutional 
Channel Features: CCF）を全て使用するのではなく、現在のフレームにおいて
「ターゲット」と「背景」を分離するのに最も有効な特徴量だけをオンラインブーステ
ィングによって動的に選択する手法である。これにより、照明条件が変化した場合には色
特徴を、形状が特徴的な場合にはエッジ特徴を重点的に利用するといった適応が可能とな
り、深層学習の表現力を活かしつつ、組み込みコンピュータ（NVIDIA Jetson TX2）上で平
均20fpsというリアルタイム処理を達成している。

評価実験では、屋内および屋外環境において、照明変化、複雑な背景、ターゲットの回転や
遮蔽が発生するシナリオで検証が行われた。その結果、提案手法はKCFやTLDといった既存の
トラッカーと比較して最も高い追跡成功率と精度を記録し、単眼カメラという限られたセン
サ構成であっても、深層学習の効率的な利用により実環境での頑健な人追従が可能であるこ
とを実証している。一方で、単眼カメラを用いる本手法は、原理的に奥行き情報の直接計測
が困難であり、かつ視野角も限定されるという課題を残している。実験においても、特定の
条件下では高い追従性能を示したものの、対象がカメラに接近しすぎた際の検出失敗や、遠
距離における距離推定精度の低下といった、センサ特性に起因する誤推定や検出不可の条件
が存在することが報告されている。

\section{PointPillars}
Langら\cite{PointPillars: Fast Encoders for Object Detection from Point Clouds}は、
自動運転やロボティクスにおいて極めて重要となる3D物体検出タスクにおいて、推論速度
と検出精度の両立を目指した新たなネットワークアーキテクチャ「PointPillars」を提案
している。

従来、点群データ（Point Cloud）を用いた3D物体検出には、点群をボクセル（Voxel）化
して3D畳み込みニューラルネットワーク（3D CNN）を適用する手法や、点群
を鳥瞰図（Bird's Eye View: BEV）などに投影して2D CNNを適用する手法が存在した。
前者は高い精度を誇る一方で計算コストが非常に高く（例：VoxelNet）、後者は高速である
ものの、3次元形状の情報を損失しやすく精度が劣るという課題があった。また、PointNet
のように点群を直接処理する手法は計算効率が良いが、大規模な点群に対するスケーラビ
リティに課題があった。これに対し、PointPillarsは、点群を垂直方向の柱（Pillar）状
に整理して処理する新しいエンコーダを採用することで、3D畳み込みを一切使用せず、標
準的な2D畳み込みのみで構成される高速かつ高精度な検出パイプラインを実現している。

アーキテクチャは、大きく分けてPillar Feature Net (PFN)、Backbone (2D CNN)、
Detection Head (SSD) の3つの部分から構成される。第一に、Pillar Feature Net (PFN)
は、生の点群データを「擬似画像（Pseudo-image）」に変換する役割を担う。まず、入力
された点群は$xy$平面上のグリッドに基づいて、垂直方向に伸びる「ピラー（Pillar）」
に分割される。各ピラー内の点は、座標 $(x, y, z)$、反射強度 $r$、幾何学的中心から
のオフセット $x_c, y_c, z_c$、ピラー中心からのオフセット $x_p, y_p$ を含む9次元
の特徴ベクトルとして表現される。これに対し、簡略化されたPointNet（線形層、Batch
Norm、ReLU）を適用することで、各点の特徴を高次元空間へ写像し、さらにピラーごとの
最大プーリング（Max Pooling）を行うことで、各ピラーを代表する特徴ベクトルを抽出
する。この処理により、点群データは $(C, H, W)$ の形式を持つ2次元の擬似画像へと
変換される。この手法は、従来のボクセルベースの手法とは異なり、垂直方向のビン（bin）
分割を行わないため、ハイパーパラメータの調整が容易であり、かつスパースなデータ
構造を効率的に扱えるという利点を持つ。第二に、Backboneネットワークは、生成された
擬似画像を入力とし、2D CNNを用いて高レベルな特徴抽出を行う。このバックボーンは、
特徴マップの解像度を下げるダウンサンプリングブロックと、それらを元の解像度に合わ
せてアップサンプリングして結合するブロックから構成されており、異なる受容野
（Receptive Field）を持つ特徴を統合することで、様々なサイズの物体に対応可能な表現
を獲得している。第三に、Detection Headには、物体検出で広く用いられているSingle 
Shot Detector (SSD) が採用されている。これにより、バックボーンからの出力特徴
マップに基づき、3Dバウンディングボックスの回帰（位置、サイズ、角度）およびクラス
分類を行う。

評価実験において、PointPillarsはKITTI 3D物体検出ベンチマークにおいて、従来の
最高精度を誇る手法（MV3D, VoxelNet, SECONDなど）を凌駕する性能（BEVおよび3D検出
の両方において）を示した。特筆すべきは、その推論速度であり、デスクトップGPU上で
62 Hzという極めて高速な動作を実現している。これは、3D畳み込みを排除し、最適化さ
れた2D畳み込み演算のみを使用したことによる成果である。さらに、固定エンコーダ
（手動設計された特徴量）を使用する従来手法と比較しても、学習可能なエンコーダ
（Learned Encoder）を使用することで、速度を犠牲にすることなく大幅な精度向上を達成
していることが実証されている。

Langらによって提案されたPointPillars は、推論速度と検出精度のバランスにおいて優れ
た手法であるが、その構造上の特性に起因するいくつかの技術的課題も明らかになっている。
まず、類似した幾何学的特徴を持つ対象の識別において誤検知が生じやすいという点が挙げ
られる。PointPillarsは点群を垂直方向のピラーに圧縮して特徴抽出を行うため、高さ方向
の詳細情報が抽象化される過程で、ポールや木の幹といった細長い垂直構造物を歩行者とし
て誤認する事例や、歩行者とサイクリストを互いに誤分類する事例が報告されている。また
、乗用車（Car）の検出においても、バンやトラムといった類似形状の車両クラスを誤って
検出するケース（False Positive）が確認されている。
次に、観測条件が悪い状況下での検出能力の限界である。他のLiDARベースの手法と同様に、
対象が他の物体によって部分的に遮蔽（オクルージョン）されている場合や、センサから
遠く離れており点群密度が極端に低い場合において、検出漏れ（False Negative）が発生
しやすい傾向がある。さらに、空間解像度と処理速度の間にトレードオフが存在する点も
課題である。推論速度を優先してグリッドサイズを大きく設定すると、車両のような大きな
物体の検出性能は維持されるものの、歩行者やサイクリストといった小規模な対象の検出
精度が低下することがアブレーションスタディによって示されている。したがって、実環境
で多様な対象を同時にかつ高速に検出するためには、このトレードオフを慎重に調整する
必要がある。



\section{ReID3D}
Guoらは、公共のセキュリティや監視システムにおいて重要な役割を担う人物再同定
（Person Re-identification: ReID）タスクにおいて、従来のカメラベースの手法が抱える
環境依存性の問題を克服するため、LiDARセンサーのみを用いた新たなフレームワーク
「ReID3D」を提案している。 RGBカメラを用いた従来のReID手法には、服装の色や
テクスチャといった外見情報（Appearance）に強く依存しているという根本的な課題がある。
そのため、夜間や低照度環境では視覚情報が欠落し、また複雑な背景においては視覚的な
曖昧さが増大するため、識別精度が著しく低下してしまう。 この問題に対し、深度情報を
利用するアプローチとしてKinectやミリ波レーダーを用いる研究も存在するが、Kinectは
屋内利用に限られ計測範囲が狭く、レーダーは解像度が低いため人物の詳細な識別が困難
であるという制約が存在した。

これらの課題を解決するため、Guoらは、照明条件に影響されず、かつ長距離でも高精度な
3D構造情報を取得可能なLiDARに着目した。彼らは、LiDAR点群から、身長や体型、歩行
（Gait）といった本質的な特徴（Intrinsic Features）を抽出することで、服装の変化や
暗闇にも頑健なReIDの実現を目指した。しかし、LiDARを用いたReIDの研究は前例がなく、
学習に必要なデータセットが存在しないことが大きな障壁となっていた。 このデータ不足
を解決するため、著者らは初の実環境LiDAR ReIDデータセット「LReID」およびシミュレー
ションデータセット「LReID-sync」を構築した。LReIDは屋外の多様な環境下で収集された
320名のIDを含む実データであり、LReID-syncはUnity3Dを用いて生成された600名の合成
データである。

本手法の中核となるのは、点群データの希薄性（Sparsity）と単一視点による情報の欠落を
補うための「マルチタスク事前学習（Multi-task Pre-training）」戦略である。
まずLReID-syncを用いてエンコーダを学習させる際、欠損した点群から完全な全体形状
を復元する「点群補完（Point Cloud Completion）」と、人体モデルのパラメータを推定
する「SMPLパラメータ学習」という二つのタスクを課すことで、エンコーダに人体の
幾何学的構造を事前に獲得させ、実データでの学習を効果的に支援している。また、
ReIDネットワークには、新たに設計された「Graph-based Complementary Enhancement 
Encoder (GCEE)」が採用された。GCEEは、特徴空間上で動的にグラフを構築するGCNを
バックボーンとし、「Eraser」モジュールを持つComplementary Feature Extractor (CFE) 
を導入している。CFEは、あるフレームから抽出した主要な特徴を次のフレームから消去
（Erase）して処理することで、フレーム間の情報の重複を排除し、より包括的で識別性
の高い特徴抽出を可能にしている。さらに、時系列情報の統合にはTransformerが用
いられ、歩行動作などの動的特徴を効率的に集約している。

評価実験において、ReID3Dは構築されたLReIDデータセット上で、カメラベースの最先端手
法（TCLNetなど）と比較して圧倒的なロバスト性を示した。特に低照度環境下においては、
カメラベース手法の精度が大幅に低下する中、ReID3DはRank-1精度で93.3\%
（全体では94.0\%）という高い性能を達成し、照明条件に左右されないLiDARの優位性を
実証した。 結論として、ReID3Dは、シミュレーションデータを活用した事前学習と、
点群の特性に特化したGCEEを組み合わせることで、LiDAR点群から個人の本質的な3D特徴を
抽出することに成功し、従来のカメラだけでは困難であった悪条件下での人物再同定という
課題を解決した先駆的な研究であるといえる。

ReID3Dは、低照度環境や幾何学的構造の取得において優れた性能を示す一方で、十分な照度
が確保された明所（Normal light）環境においては、ビデオベースの最先端手法と比較して
認識精度が劣るという課題が確認されている。 これは、ビデオベースの手法が、明るい環
境下で得られるリッチな外見情報（服装の色、柄、テクスチャなど）を最大限に活用できる
のに対し、LiDARベースの手法であるReID3Dは、形状情報と反射強度のみに依存し、色彩情
報を利用できないことに起因している。また、特徴空間の可視化分析において、ReID3Dは、
カメラベースの手法であれば容易に識別可能な特定の歩行者の識別に失敗するケースも報告
されている。これらの結果は、LiDARとカメラがそれぞれ異なるモダリティの特性を持って
おり、互いに補完的な関係にあることを示唆している。



\section{従来研究における課題と本研究の位置づけ}
自律移動ロボットの人追従走行において、オクルージョン発生時の堅牢性は未だ解決すべき
重要な課題である。 2D LiDARを用いた手法は計算コストが低い反面、取得情報が水平断面
に限られるため、オクルージョン後の再識別やロスト状態からの自律的な復帰が困難であ
る。 一方、3D LiDARを用いた手法は詳細な空間情報を取得できるが、既存研究の多くは追
跡の連続性に主眼を置いており、遮蔽により追跡が完全に途切れた後の再識別や復帰手法
については十分に確立されていない。 また、単眼カメラは外見情報を用いた再識別に優れ
るものの、視野の制約によるフレームアウトや照明条件の変化に弱いという課題がある。

そこで本研究では、ロボット向けの全方位3D LiDAR「Livox Mid-360」を用いた人追従シス
テムを提案する。全方位視野により対象のフレームアウトを防ぎつつ、点群データを活用
してオクルージョン後の再検出・再識別を行うことで、複雑な環境下でも自律的に追従を
継続できるシステムの構築を目指す。