\relax 
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\citation{深層学習を用いた人追従機能の開発}
\citation{深層学習を用いた人追従機能の開発}
\citation{Temporal convolutional networks for multi-person activity recognition using a 2D LIDAR}
\citation{Temporal convolutional networks for multi-person activity recognition using a 2D LIDAR}
\citation{Temporal convolutional networks for multi-person activity recognition using a 2D LIDAR}
\citation{Tracking People in a Mobile Robot From 2D LIDAR Scans Using Full Convolutional Neural Networks for Security in Cluttered Environments}
\citation{Tracking People in a Mobile Robot From 2D LIDAR Scans Using Full Convolutional Neural Networks for Security in Cluttered Environments}
\citation{Tracking People in a Mobile Robot From 2D LIDAR Scans Using Full Convolutional Neural Networks for Security in Cluttered Environments}
\citation{A Robust Autonomous Following Method for Mobile Robots in Dynamic Environments}
\citation{A Robust Autonomous Following Method for Mobile Robots in Dynamic Environments}
\citation{A Robust Autonomous Following Method for Mobile Robots in Dynamic Environments}
\citation{A Robust Autonomous Following Method for Mobile Robots in Dynamic Environments}
\citation{A Robust Autonomous Following Method for Mobile Robots in Dynamic Environments}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\citation{深層学習を用いた人追従機能の開発}
\citation{Temporal convolutional networks for multi-person activity recognition using a 2D LIDAR}
\citation{Tracking People in a Mobile Robot From 2D LIDAR Scans Using Full Convolutional Neural Networks for Security in Cluttered Environments}
\citation{A Robust Autonomous Following Method for Mobile Robots in Dynamic Environments}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\citation{統計からみた我が国の高齢者}
\citation{高齢化の現状と将来像}
\citation{近年の建設工事用ロボット開発について}
\citation{既存AGVを超える特長を持った協働運搬ロボット「サウザー」}
\citation{深層学習を用いた人追従機能の開発}
\citation{People Detection and Tracking Using LIDAR Sensors}
\citation{Temporal convolutional networks for multi-person activity recognition using a 2D LIDAR}
\citation{Tracking People in a Mobile Robot From 2D LIDAR Scans Using Full Convolutional Neural Networks for Security in Cluttered Environments}
\citation{Tracking People Using Ankle-Level 2D LiDAR for Gait Analysis}
\citation{A Robust Autonomous Following Method for Mobile Robots in Dynamic Environments}
\@writefile{toc}{\contentsline {chapter}{\numberline {Chapter\ 1}Introduction}{1}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}はじめに}{1}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {1.2}論文構成}{2}{}\protected@file@percent }
\citation{深層学習を用いた人追従機能の開発}
\citation{深層学習を用いた人追従機能の開発}
\citation{深層学習を用いた人追従機能の開発}
\citation{深層学習を用いた人追従機能の開発}
\citation{深層学習を用いた人追従機能の開発}
\citation{深層学習を用いた人追従機能の開発}
\citation{深層学習を用いた人追従機能の開発}
\@writefile{toc}{\contentsline {chapter}{\numberline {Chapter\ 2}Related Work}{3}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}2D-LiDARとYOLOv5を用いた手法}{3}{}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {2.1}{\ignorespaces {Success rate of emergency stops on each road (著者\cite  {深層学習を用いた人追従機能の開発}から転載)} }}{3}{}\protected@file@percent }
\newlabel{2-1_Success rate of emergency stops on each road}{{2.1}{3}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Image of centroid (著者\cite  {深層学習を用いた人追従機能の開発}から転載)}}{4}{}\protected@file@percent }
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{2-1_Image of centroid}{{2.1}{4}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Data Acquisition Environment (著者\cite  {深層学習を用いた人追従機能の開発}から転載)}}{4}{}\protected@file@percent }
\newlabel{2-1_Data Acquisition Environment}{{2.2}{4}{}{}{}}
\citation{Temporal convolutional networks for multi-person activity recognition using a 2D LIDAR}
\citation{Temporal convolutional networks for multi-person activity recognition using a 2D LIDAR}
\citation{Temporal convolutional networks for multi-person activity recognition using a 2D LIDAR}
\citation{Temporal convolutional networks for multi-person activity recognition using a 2D LIDAR}
\citation{Temporal convolutional networks for multi-person activity recognition using a 2D LIDAR}
\citation{Temporal convolutional networks for multi-person activity recognition using a 2D LIDAR}
\citation{Temporal convolutional networks for multi-person activity recognition using a 2D LIDAR}
\citation{Temporal convolutional networks for multi-person activity recognition using a 2D LIDAR}
\citation{Temporal convolutional networks for multi-person activity recognition using a 2D LIDAR}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}2D-LiDARの距離データをクラスタリングする手法}{5}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Human recognition (著者\cite  {Temporal convolutional networks for multi-person activity recognition using a 2D LIDAR}から転載)}}{5}{}\protected@file@percent }
\newlabel{2-2_Human recognition}{{2.3}{5}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces LIDAR data processing (著者\cite  {Temporal convolutional networks for multi-person activity recognition using a 2D LIDAR}から転載)}}{6}{}\protected@file@percent }
\newlabel{2-2_LIDAR data processing}{{2.4}{6}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces Kitchen scenario (著者\cite  {Temporal convolutional networks for multi-person activity recognition using a 2D LIDAR}から転載)}}{6}{}\protected@file@percent }
\newlabel{2-2_Kitchen scenario}{{2.5}{6}{}{}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2.2}{\ignorespaces {THE EFFECT OF TRAJECTORY AUGMENTATION (著者\cite  {Temporal convolutional networks for multi-person activity recognition using a 2D LIDAR}から転載)} }}{6}{}\protected@file@percent }
\newlabel{2-2_THE EFFECT OF TRAJECTORY AUGMENTATION}{{2.2}{6}{}{}{}}
\citation{Tracking People in a Mobile Robot From 2D LIDAR Scans Using Full Convolutional Neural Networks for Security in Cluttered Environments}
\citation{Tracking People in a Mobile Robot From 2D LIDAR Scans Using Full Convolutional Neural Networks for Security in Cluttered Environments}
\citation{Tracking People in a Mobile Robot From 2D LIDAR Scans Using Full Convolutional Neural Networks for Security in Cluttered Environments}
\citation{Tracking People in a Mobile Robot From 2D LIDAR Scans Using Full Convolutional Neural Networks for Security in Cluttered Environments}
\citation{Tracking People in a Mobile Robot From 2D LIDAR Scans Using Full Convolutional Neural Networks for Security in Cluttered Environments}
\citation{Tracking People in a Mobile Robot From 2D LIDAR Scans Using Full Convolutional Neural Networks for Security in Cluttered Environments}
\citation{Tracking People in a Mobile Robot From 2D LIDAR Scans Using Full Convolutional Neural Networks for Security in Cluttered Environments}
\citation{Tracking People in a Mobile Robot From 2D LIDAR Scans Using Full Convolutional Neural Networks for Security in Cluttered Environments}
\citation{Tracking People in a Mobile Robot From 2D LIDAR Scans Using Full Convolutional Neural Networks for Security in Cluttered Environments}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}FCNと2D-LiDARを用いた手法}{7}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces Architecture of the CNN used by PeTra (著者\cite  {Tracking People in a Mobile Robot From 2D LIDAR Scans Using Full Convolutional Neural Networks for Security in Cluttered Environments}から転載)}}{7}{}\protected@file@percent }
\newlabel{2-4_cnn}{{2.6}{7}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.7}{\ignorespaces Robotics mobile lab plan (left), Orbi-One robot (center), and KIO RTLS anchors (right). (著者\cite  {Tracking People in a Mobile Robot From 2D LIDAR Scans Using Full Convolutional Neural Networks for Security in Cluttered Environments}から転載)}}{8}{}\protected@file@percent }
\newlabel{2-4_env}{{2.7}{8}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.8}{\ignorespaces Comparison image of PeTra and LD by Rviz (著者\cite  {Tracking People in a Mobile Robot From 2D LIDAR Scans Using Full Convolutional Neural Networks for Security in Cluttered Environments}から転載)}}{8}{}\protected@file@percent }
\newlabel{2-4_result}{{2.8}{8}{}{}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2.3}{\ignorespaces {Mean error and standard deviation[m] at each location (著者\cite  {Tracking People in a Mobile Robot From 2D LIDAR Scans Using Full Convolutional Neural Networks for Security in Cluttered Environments}を改変)} }}{8}{}\protected@file@percent }
\newlabel{2-4_result_table}{{2.3}{8}{}{}{}}
\citation{A Robust Autonomous Following Method for Mobile Robots in Dynamic Environments}
\citation{A Robust Autonomous Following Method for Mobile Robots in Dynamic Environments}
\citation{A Robust Autonomous Following Method for Mobile Robots in Dynamic Environments}
\citation{A Robust Autonomous Following Method for Mobile Robots in Dynamic Environments}
\citation{A Robust Autonomous Following Method for Mobile Robots in Dynamic Environments}
\citation{A Robust Autonomous Following Method for Mobile Robots in Dynamic Environments}
\citation{A Robust Autonomous Following Method for Mobile Robots in Dynamic Environments}
\citation{A Robust Autonomous Following Method for Mobile Robots in Dynamic Environments}
\citation{A Robust Autonomous Following Method for Mobile Robots in Dynamic Environments}
\citation{A Robust Autonomous Following Method for Mobile Robots in Dynamic Environments}
\citation{A Robust Autonomous Following Method for Mobile Robots in Dynamic Environments}
\citation{A Robust Autonomous Following Method for Mobile Robots in Dynamic Environments}
\citation{A Robust Autonomous Following Method for Mobile Robots in Dynamic Environments}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}AOAタグと2D-LiDARを組み合わせた手法}{9}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {2.9}{\ignorespaces Person following in environments with obstacles (著者\cite  {A Robust Autonomous Following Method for Mobile Robots in Dynamic Environments}から転載)}}{10}{}\protected@file@percent }
\newlabel{2-3_real}{{2.9}{10}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.10}{\ignorespaces The architecture of our person-following system (著者\cite  {A Robust Autonomous Following Method for Mobile Robots in Dynamic Environments}から転載)}}{10}{}\protected@file@percent }
\newlabel{2-3_system}{{2.10}{10}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.11}{\ignorespaces Human legs detection and human tracking (著者\cite  {A Robust Autonomous Following Method for Mobile Robots in Dynamic Environments}から転載)}}{10}{}\protected@file@percent }
\newlabel{2-3_overview}{{2.11}{10}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.12}{\ignorespaces Kalman filter tracking in occluded environments (著者\cite  {A Robust Autonomous Following Method for Mobile Robots in Dynamic Environments}から転載)}}{11}{}\protected@file@percent }
\newlabel{2-3_aoaANDlaser}{{2.12}{11}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.13}{\ignorespaces Following trajectory in environments with obstacles (著者\cite  {A Robust Autonomous Following Method for Mobile Robots in Dynamic Environments}から転載)}}{11}{}\protected@file@percent }
\newlabel{2-3_result}{{2.13}{11}{}{}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2.4}{\ignorespaces {Comparison of performance between FMM-DWA algorithm and MPEPC algorithm (著者\cite  {A Robust Autonomous Following Method for Mobile Robots in Dynamic Environments}から転載)} }}{11}{}\protected@file@percent }
\newlabel{2-3_result_table}{{2.4}{11}{}{}{}}
\@writefile{toc}{\contentsline {section}{\numberline {2.5}従来研究における課題と本プロジェクトの位置づけ}{12}{}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {Chapter\ 3}Method}{13}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}概要}{13}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.2}要求仕様}{13}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {3.3}システム構成}{14}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces System configuration chart}}{14}{}\protected@file@percent }
\newlabel{System configuration chart}{{3.1}{14}{}{}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}ソフトウェア構成}{15}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Software configuration diagram}}{15}{}\protected@file@percent }
\newlabel{Software configuration diagram}{{3.2}{15}{}{}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.5}データセットの作成}{16}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Example of an overhead view image}}{17}{}\protected@file@percent }
\newlabel{Example of an overhead view image}{{3.3}{17}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces Example data sets}}{17}{}\protected@file@percent }
\newlabel{Example data sets}{{3.4}{17}{}{}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.6}YOLOv8による学習}{18}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces Training results}}{18}{}\protected@file@percent }
\newlabel{Training results}{{3.5}{18}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.6}{\ignorespaces Example of inference results with YOLOv8 using learned weights}}{18}{}\protected@file@percent }
\newlabel{Example of inference results with YOLOv8 using learned weights}{{3.6}{18}{}{}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.7}追従目標の特定}{19}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {3.7}{\ignorespaces Multiple leg sections detected on both legs}}{19}{}\protected@file@percent }
\newlabel{yolo image}{{3.7}{19}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.8}{\ignorespaces Target identification methods}}{19}{}\protected@file@percent }
\newlabel{Target identification methods}{{3.8}{19}{}{}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.8}ロボット台車の制御}{20}{}\protected@file@percent }
\newlabel{angularPID}{{3.1}{20}{}{}{}}
\newlabel{angularPD}{{3.2}{20}{}{}{}}
\newlabel{linearPID}{{3.3}{20}{}{}{}}
\@writefile{toc}{\contentsline {chapter}{\numberline {Chapter\ 4}Experiments}{21}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}実験目的}{21}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {4.2}実験方法}{21}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}実験機材}{22}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Happy Edu}}{22}{}\protected@file@percent }
\newlabel{Happy Edu}{{4.1}{22}{}{}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces {ASUS ROG Strix G16 specification}}}{22}{}\protected@file@percent }
\newlabel{ASUS ROG Strix G16 specification}{{4.1}{22}{}{}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.2}{\ignorespaces {TurtleBot3 Big Wheel specification}}}{23}{}\protected@file@percent }
\newlabel{TurtleBot3 Big Wheel specification}{{4.2}{23}{}{}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4.3}{\ignorespaces {UTM30-LX specification}}}{23}{}\protected@file@percent }
\newlabel{UTM30-LX specification}{{4.3}{23}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.2}追従実験}{23}{}\protected@file@percent }
\newlabel{Success rate}{{4.1}{23}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces Image of tracking experiment environment (FMT Laboratory Room 206)}}{24}{}\protected@file@percent }
\newlabel{Image of tracking experiment environment (FMT Laboratory Room 206)}{{4.2}{24}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces Image of tracking experiment environment (FMT Laboratory Room 326)}}{24}{}\protected@file@percent }
\newlabel{Image of tracking experiment environment (FMT Laboratory Room 326)}{{4.3}{24}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces Straight road}}{25}{}\protected@file@percent }
\newlabel{Straight road}{{4.4}{25}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces Curved road}}{25}{}\protected@file@percent }
\newlabel{Curved road}{{4.5}{25}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces Right angle road}}{25}{}\protected@file@percent }
\newlabel{Right angle road}{{4.6}{25}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.3}最大追従速度実験}{26}{}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {4.7}{\ignorespaces Maximum tracking speed experiment environment image (FMT Laboratory Room 326)}}{26}{}\protected@file@percent }
\newlabel{Maximum tracking speed experiment environment image (FMT Laboratory Room 326)}{{4.7}{26}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.8}{\ignorespaces Image of maximum tracking speed experiment}}{26}{}\protected@file@percent }
\newlabel{Image of maximum tracking speed experiment}{{4.8}{26}{}{}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}実験結果}{27}{}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.1}追従実験}{27}{}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {4.4}{\ignorespaces {Success rate of traking in each road}}}{27}{}\protected@file@percent }
\newlabel{Success rate of traking in each road}{{4.4}{27}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.9}{\ignorespaces Tracking experiment (Real view)}}{27}{}\protected@file@percent }
\newlabel{Tracking experiment (Real view)}{{4.9}{27}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.10}{\ignorespaces Tracking experiment (Internal view)}}{27}{}\protected@file@percent }
\newlabel{Tracking experiment (Internal view)}{{4.10}{27}{}{}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.2}最大追従速度実験}{28}{}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {4.5}{\ignorespaces {Maximum tracking speed experimental result}}}{28}{}\protected@file@percent }
\newlabel{Maximum tracking speed experimental result}{{4.5}{28}{}{}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.11}{\ignorespaces Tracking speed graph}}{28}{}\protected@file@percent }
\newlabel{Tracking speed graph}{{4.11}{28}{}{}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}考察}{29}{}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{\numberline {Chapter\ 5}Conclusion}{30}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}まとめ}{30}{}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.2}今後の課題}{30}{}\protected@file@percent }
\@writefile{toc}{\contentsline {chapter}{Acknowledgments}{31}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\bibcite{統計からみた我が国の高齢者}{1}
\bibcite{高齢化の現状と将来像}{2}
\bibcite{近年の建設工事用ロボット開発について}{3}
\bibcite{既存AGVを超える特長を持った協働運搬ロボット「サウザー」}{4}
\bibcite{深層学習を用いた人追従機能の開発}{5}
\bibcite{People Detection and Tracking Using LIDAR Sensors}{6}
\bibcite{Temporal convolutional networks for multi-person activity recognition using a 2D LIDAR}{7}
\bibcite{Tracking People in a Mobile Robot From 2D LIDAR Scans Using Full Convolutional Neural Networks for Security in Cluttered Environments}{8}
\bibcite{Tracking People Using Ankle-Level 2D LiDAR for Gait Analysis}{9}
\@writefile{toc}{\contentsline {chapter}{References}{32}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\bibcite{A Robust Autonomous Following Method for Mobile Robots in Dynamic Environments}{10}
\@writefile{toc}{\contentsline {chapter}{Appendices}{34}{}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{param}{{5.1}{34}{}{}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {5.1}{\ignorespaces follow\_me\_params.yaml}}{34}{}\protected@file@percent }
\newlabel{image}{{5.2}{35}{}{}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {5.2}{\ignorespaces laser\_to\_image.py}}{35}{}\protected@file@percent }
\newlabel{person}{{5.3}{38}{}{}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {5.3}{\ignorespaces person\_detector.py}}{38}{}\protected@file@percent }
\newlabel{base}{{5.4}{43}{}{}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {5.4}{\ignorespaces base\_controller.py}}{43}{}\protected@file@percent }
\newlabel{launch}{{5.5}{47}{}{}{}}
\@writefile{lol}{\contentsline {lstlisting}{\numberline {5.5}{\ignorespaces follow\_me.launch.py}}{47}{}\protected@file@percent }
\gdef \@abspage@last{54}
